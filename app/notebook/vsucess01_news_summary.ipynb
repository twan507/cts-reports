{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "import datetime as dt\n",
    "import pandas_ta as ta\n",
    "import copy\n",
    "import random\n",
    "from pymongo import MongoClient\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "import feedparser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import re\n",
    "from bs4 import Tag\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'import'))\n",
    "from import_env import load_env\n",
    "\n",
    "mongo_client = MongoClient(load_env(\"MONGO_URI\"))\n",
    "stock_db = mongo_client[\"stock_db\"]\n",
    "\n",
    "vsuccess_uri = load_env(\"VSUCCESS_URI\")\n",
    "if not vsuccess_uri:\n",
    "\traise ValueError(\"Environment variable 'VSUCCESS_URI' is not set.\")\n",
    "vsuccess_engine = create_engine(vsuccess_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_content(url):\n",
    "\n",
    "    # Set up headers for the request\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
    "    \n",
    "    try:\n",
    "        # Get webpage content\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse HTML\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        # Find article content\n",
    "        content_div = soup.find(\"div\", {\"itemprop\": \"articleBody\", \"id\": \"vst_detail\"})\n",
    "        \n",
    "        # Ensure content_div is a Tag object before proceeding\n",
    "        if not isinstance(content_div, Tag):\n",
    "            return \"\"\n",
    "        \n",
    "        # Extract text from paragraphs\n",
    "        article_content = \"\"\n",
    "        paragraphs = content_div.find_all(\"p\")\n",
    "        \n",
    "        for p in paragraphs:\n",
    "            # Skip author and publishing info\n",
    "            if p.get(\"class\") in [[\"pAuthor\"], [\"pPublishTimeSource\", \"right\"]]:\n",
    "                continue\n",
    "            \n",
    "            text = p.get_text(strip=True)\n",
    "            if text:\n",
    "                article_content += f\"{text}\\n\"\n",
    "        \n",
    "        return article_content.strip()\n",
    "        \n",
    "    except Exception:\n",
    "        return \"\"\n",
    "    \n",
    "def get_summary(model, content, news_type):\n",
    "    if news_type == 'doanh_nghiep':\n",
    "        promt = f\"\"\"\n",
    "            Hãy tóm tắt nội dung của bài báo được cung cấp dưới đây:\n",
    "            {content}\n",
    "\n",
    "            Yêu cầu cho bản tóm tắt:\n",
    "\n",
    "            1. Phân tích nội dung để xác định mã cổ phiếu chính mà bài báo tập trung đề cập hoặc phân tích.\n",
    "            2. Bản tóm tắt phải bắt đầu bằng chính mã cổ phiếu đó, theo định dạng: [MÃ CỔ PHIẾU]: Nội dung tóm tắt... (Ví dụ: HPG: Công ty vừa công bố kế hoạch mở rộng sản xuất thép...).\n",
    "            3. Nội dung tóm tắt theo sau là một đoạn văn liền mạch, khoảng 30 từ, trình bày các thông tin cốt lõi liên quan đến mã cổ phiếu đó từ bài báo.\n",
    "            4. Nếu bài báo không đề cập đến mã cổ phiếu cụ thể nào một cách rõ ràng, hoặc không có mã nào là trọng tâm thì trình bày nội dung tóm tắt như bình thường, không cần bắt đầu bằng mã cổ phiếu.\n",
    "            5. Phần nội dung bắt đầu trực tiếp bằng thông tin chính của bài báo, không sử dụng các cụm từ giới thiệu như \"Bài báo này nói về...\", \"Theo bài báo thì...\", \"Nội dung của bài viết là...\". Hãy hành văn như đang cung cấp tin tức.\n",
    "            6. Đặc biệt quan trọng: Phải bao gồm đầy đủ và chính xác tất cả các số liệu cụ thể đã được đề cập trong bài báo gốc. Vui lòng viết bằng tiếng Việt.\n",
    "        \"\"\"\n",
    "    else:\n",
    "        promt = f\"\"\"\n",
    "            Hãy tóm tắt nội dung của bài báo được cung cấp dưới đây:\n",
    "            {content}\n",
    "\n",
    "            Yêu cầu cho bản tóm tắt:\n",
    "\n",
    "            1. Trình bày thành một đoạn văn duy nhất, liền mạch.\n",
    "            2. Bắt đầu trực tiếp bằng thông tin chính của bài báo, không sử dụng các cụm từ giới thiệu như \"Bài báo này nói về...\", \"Theo bài báo thì...\", \"Nội dung của bài viết là...\". Hãy hành văn như đang cung cấp tin tức.\n",
    "            3. Tổng độ dài toàn bộ các mẩu tin khoảng 30 từ.\n",
    "            4. Đặc biệt quan trọng: Phải bao gồm đầy đủ và chính xác tất cả các số liệu cụ thể đã được đề cập trong bài báo gốc. Vui lòng viết bằng tiếng Việt.\n",
    "        \"\"\"\n",
    "\n",
    "    response = model.generate_content(promt)\n",
    "    return response.text\n",
    "\n",
    "def split_news_content(content):\n",
    "    points = content.split('- ')\n",
    "    cleaned_points = []\n",
    "    for point in points:\n",
    "        point = point.strip()\n",
    "        if point:\n",
    "            cleaned_points.append(point)\n",
    "    \n",
    "    return cleaned_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_url_dict = {\n",
    "    'vi_mo': {\n",
    "        'vi_mo': 'https://vietstock.vn/761/kinh-te/vi-mo.rss',\n",
    "        'kinh_te_dau_tu': 'https://vietstock.vn/768/kinh-te/kinh-te-dau-tu.rss',\n",
    "    },\n",
    "    'chinh_sach': {\n",
    "        'chinh_sach': 'https://vietstock.vn/143/chung-khoan/chinh-sach.rss',\n",
    "    },\n",
    "    'quoc_te': {\n",
    "        'tai_chinh_quoc_te': 'https://vietstock.vn/772/the-gioi/tai-chinh-quoc-te.rss',\n",
    "        'chung_khoan_the_gioi': 'https://vietstock.vn/773/the-gioi/chung-khoan-the-gioi.rss',\n",
    "    },\n",
    "    'doanh_nghiep': {\n",
    "        'hoat_dong_kinh_doanh': 'https://vietstock.vn/737/doanh-nghiep/hoat-dong-kinh-doanh.rss',\n",
    "    }\n",
    "}\n",
    "\n",
    "genai.configure(api_key=load_env(\"GEMINI_API\")) # type: ignore\n",
    "# gemini = genai.GenerativeModel('gemini-2.5-flash-preview-04-17-thinking') # type: ignore\n",
    "gemini = genai.GenerativeModel('gemini-2.0-flash') # type: ignore\n",
    "\n",
    "full_news_df_dict = {}\n",
    "for news_type, url_dict in rss_url_dict.items():\n",
    "    temp_news_list = []\n",
    "    max_entries = 1 if news_type in ['doanh_nghiep', 'chinh_sach'] else 1\n",
    "    \n",
    "    for url in url_dict.values():\n",
    "        feed = feedparser.parse(url)\n",
    "        for entry in feed.entries[:max_entries]:\n",
    "            content = get_article_content(entry['id'])\n",
    "            \n",
    "            # Lấy thời gian đăng bài từ RSS feed\n",
    "            published_time = \"\"\n",
    "            if hasattr(entry, 'published') and entry.published:\n",
    "                published_time = entry.published\n",
    "            \n",
    "            temp_news_list.append({\n",
    "                'title': entry['title'], \n",
    "                # 'content': get_summary(gemini, content, news_type),\n",
    "                'content': content,\n",
    "                'published_time': published_time\n",
    "            })\n",
    "            # time.sleep(2)\n",
    "    full_news_df_dict[news_type] = temp_news_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_news_dict = {}\n",
    "for news_type in full_news_df_dict.keys():\n",
    "    filtered_news_list = []\n",
    "    for item in full_news_df_dict[news_type]:\n",
    "        content = item['content']\n",
    "        if 'bài báo' in content.lower():\n",
    "            continue\n",
    "        # Đếm số từ\n",
    "        word_count = len(content.split())\n",
    "        # Kiểm tra số từ trong khoảng 40-60\n",
    "        if 40 <= word_count <= 70:\n",
    "            filtered_news_list.append(item)\n",
    "        else:\n",
    "            print(f\"Đã loại {news_type} với số từ: {word_count}\")\n",
    "\n",
    "\n",
    "    filtered_news_dict[news_type] = filtered_news_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for news_type, news_list in filtered_news_dict.items():\n",
    "    # Create a temporary DataFrame for sorting\n",
    "    temp_df = pd.DataFrame(news_list)\n",
    "    if not temp_df.empty and 'published_time' in temp_df.columns:\n",
    "        # Convert 'published_time' to datetime objects using the correct format\n",
    "        # RFC 822 format (common in RSS feeds) uses abbreviated month names (%b)\n",
    "        temp_df['published_time'] = pd.to_datetime(\n",
    "            temp_df['published_time'],\n",
    "            format=\"%a, %d %b %Y %H:%M:%S %z\", \n",
    "            errors='coerce'  # If a date can't be parsed with this format, it becomes NaT\n",
    "        )\n",
    "        \n",
    "        # Drop rows where 'published_time' could not be converted (is NaT)\n",
    "        temp_df.dropna(subset=['published_time'], inplace=True)\n",
    "        \n",
    "        if not temp_df.empty: # Proceed only if temp_df has valid, parsed dates\n",
    "            temp_df = temp_df.sort_values(by='published_time', ascending=False)\n",
    "            \n",
    "            for index, row in enumerate(temp_df.itertuples(), 1):\n",
    "                data_list.append({\n",
    "                    'news_type': news_type,\n",
    "                    'news_number': index,\n",
    "                    'title': row.title,\n",
    "                    'content': row.content,\n",
    "                    'published_time': row.published_time # This is now a timezone-aware datetime object\n",
    "                })\n",
    "\n",
    "daily_news_df = pd.DataFrame(data_list)\n",
    "\n",
    "if not daily_news_df.empty and 'published_time' in daily_news_df.columns and pd.api.types.is_datetime64_any_dtype(daily_news_df['published_time']):\n",
    "    daily_news_df['published_time'] = daily_news_df['published_time'].dt.tz_convert('Asia/Ho_Chi_Minh').dt.tz_localize(None)\n",
    "elif not daily_news_df.empty and 'published_time' in daily_news_df.columns: # Handle cases where column might exist but not as datetime64 (e.g. all NaT)\n",
    "    # Attempt conversion if not already datetime, though previous steps should ensure it\n",
    "    daily_news_df['published_time'] = pd.to_datetime(daily_news_df['published_time'], errors='coerce')\n",
    "    daily_news_df.dropna(subset=['published_time'], inplace=True) # drop if conversion failed\n",
    "    if not daily_news_df.empty and pd.api.types.is_datetime64_any_dtype(daily_news_df['published_time']):\n",
    "        daily_news_df['published_time'] = daily_news_df['published_time'].dt.tz_convert('Asia/Ho_Chi_Minh').dt.tz_localize(None)\n",
    "\n",
    "daily_news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_news_df.to_sql('daily_news_df', vsuccess_engine, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
